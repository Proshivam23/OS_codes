{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 12) (1281467040.py, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 12\u001b[1;36m\u001b[0m\n\u001b[1;33m    url ='/kaggle/input/breast-\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unterminated string literal (detected at line 12)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the breast cancer dataset\n",
    "# You can replace the path with the actual path to your dataset\n",
    "url = '/kaggle/input/breast-cancer/Breast_Cancer.csv'\n",
    "breast_cancer = pd.read_csv(url)\n",
    "\n",
    "# Assuming the target variable is in a column named 'Status' and you want to classify it\n",
    "X = breast_cancer.drop('Status', axis=1)\n",
    "y = breast_cancer['Status']\n",
    "\n",
    "# Convert categorical variables to numeric using one-hot encoding\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Binarize the 'Status' column for classification\n",
    "y_class = (y == 'Alive').astype(int)  # Binary classification\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_class, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a decision tree classifier with reduced max depth for better visualization\n",
    "dt_classifier = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Visualize the decision tree with reduced max depth\n",
    "plt.figure(figsize=(15, 10))\n",
    "plot_tree(dt_classifier, filled=True, feature_names=list(X.columns), class_names=['Not Alive', 'Alive'], max_depth=3)\n",
    "plt.title(\"Decision Tree Visualization for Breast Cancer Dataset (Max Depth=3)\")\n",
    "plt.show()\n",
    "\n",
    "# Display the decision tree rules\n",
    "tree_rules = export_text(dt_classifier, feature_names=list(X.columns), max_depth=3)\n",
    "print(\"Decision Tree Rules:\\n\", tree_rules)\n",
    "\n",
    "# Plot the feature importances\n",
    "importances = dt_classifier.feature_importances_\n",
    "features = X.columns\n",
    "\n",
    "plt.barh(range(len(importances)), importances, align=\"center\")\n",
    "plt.yticks(range(len(importances)), features)\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.title(\"Decision Tree Feature Importances\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Python script uses the scikit-learn library to create a decision tree classifier for the breast cancer dataset. The goal is to predict the 'Status' of a patient, which is assumed to be either 'Alive' or 'Not Alive'.\n",
    "\n",
    "The script begins by importing the necessary libraries. It then loads the breast cancer dataset from a specified URL into a pandas DataFrame. The 'Status' column, which is the target variable, is separated from the rest of the dataset. The remaining columns, which are the features, are stored in `X`. If there are any categorical variables in the features, they are converted to numeric using one-hot encoding.\n",
    "\n",
    "The 'Status' column is binarized for classification, meaning it's converted into a binary format: 'Alive' is represented as 1 and 'Not Alive' as 0. This is stored in `y_class`.\n",
    "\n",
    "The dataset is then split into a training set and a test set, with 80% of the data used for training and 20% used for testing. This is done using the `train_test_split` function from scikit-learn.\n",
    "\n",
    "A decision tree classifier is created with a maximum depth of 3 to keep the tree small and easier to visualize. The classifier is trained using the training data.\n",
    "\n",
    "The trained classifier is then used to make predictions on the test set. The accuracy of these predictions is calculated by comparing them to the actual statuses in the test set.\n",
    "\n",
    "The decision tree is visualized using matplotlib and scikit-learn's `plot_tree` function. The tree is displayed with nodes colored according to the class, and with the feature names and class names labeled.\n",
    "\n",
    "The rules of the decision tree are displayed using the `export_text` function from scikit-learn. This provides a text representation of the decision tree, showing the conditions for each split in the tree.\n",
    "\n",
    "Finally, the feature importances are plotted in a horizontal bar chart. Feature importance gives a score for each feature of the data, the higher the score more important or relevant is the feature towards the output variable. This can help in understanding which features are most influential in the decision-making process of the classifier."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
