{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the medical dataset\n",
    "# You can replace the url with the actual path to your dataset\n",
    "url = '/kaggle/input/ckdisease/kidney_disease.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Handling missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "df['rbc'] = label_encoder.fit_transform(df['rbc'])\n",
    "df['pc'] = label_encoder.fit_transform(df['pc'])\n",
    "df['pcc'] = label_encoder.fit_transform(df['pcc'])\n",
    "df['ba'] = label_encoder.fit_transform(df['ba'])\n",
    "# ... Repeat this for other categorical columns\n",
    "\n",
    "# Select features and target variable\n",
    "X = df.drop('classification', axis=1)\n",
    "y = df['classification']\n",
    "\n",
    "# Convert categorical variables to numerical using one-hot encoding\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Create a Gaussian Naive Bayes classifier\n",
    "nb_classifier = GaussianNB()\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = nb_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Display the confusion matrix\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Display classification report\n",
    "classification_report = metrics.classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", classification_report)\n",
    "\n",
    "# Visualize the confusion matrix using a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Python script uses the scikit-learn library to create a Gaussian Naive Bayes classifier for a kidney disease dataset. The goal is to predict the 'classification' of a patient, which could be the presence or absence of kidney disease.\n",
    "\n",
    "The script starts by importing the necessary libraries. It then loads the kidney disease dataset from a specified URL into a pandas DataFrame. Any missing values in the dataset are dropped using the `dropna()` function.\n",
    "\n",
    "The script then encodes categorical variables in the dataset using a LabelEncoder. This converts categories into numerical values, which are required for the Naive Bayes classifier. The columns 'rbc', 'pc', 'pcc', and 'ba' are encoded in this way. If there are other categorical columns in the dataset, they should be encoded in the same manner.\n",
    "\n",
    "The 'classification' column, which is the target variable, is separated from the rest of the dataset. The remaining columns, which are the features, are stored in `X`. If there are any categorical variables in the features, they are converted to numeric using one-hot encoding.\n",
    "\n",
    "The dataset is then split into a training set and a test set, with 80% of the data used for training and 20% used for testing. This is done using the `train_test_split` function from scikit-learn. The `stratify` parameter is set to `y`, which means that the split will preserve the proportion of target class instances in both the training and test sets.\n",
    "\n",
    "A Gaussian Naive Bayes classifier is created and trained using the training data. The trained classifier is then used to make predictions on the test set.\n",
    "\n",
    "The accuracy of these predictions is calculated by comparing them to the actual classifications in the test set. The confusion matrix, which shows the number of true positive, true negative, false positive, and false negative predictions, is also displayed. A classification report, which includes precision, recall, f1-score, and support for each class, is printed as well.\n",
    "\n",
    "Finally, the confusion matrix is visualized using a heatmap from the seaborn library. The x and y labels of the heatmap correspond to the classes of the target variable. The color of each cell in the heatmap corresponds to the number of instances of each class in the confusion matrix."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
